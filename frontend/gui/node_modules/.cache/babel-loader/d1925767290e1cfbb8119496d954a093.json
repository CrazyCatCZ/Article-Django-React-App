{"ast":null,"code":"'use strict';\n\nconst Busboy = require('busboy');\n\nconst {\n  WriteStream\n} = require('fs-capacitor');\n\nconst createError = require('http-errors');\n\nconst isObject = require('isobject');\n\nconst objectPath = require('object-path');\n\nconst {\n  SPEC_URL\n} = require('../private/constants');\n\nconst ignoreStream = require('../private/ignoreStream');\n\nconst Upload = require('./Upload');\n/**\n * Processes a [GraphQL multipart request](https://github.com/jaydenseric/graphql-multipart-request-spec).\n * It parses the `operations` and `map` fields to create an\n * [`Upload`]{@link Upload} instance for each expected file upload, placing\n * references wherever the file is expected in the\n * [GraphQL operation]{@link GraphQLOperation} for the\n * [`Upload` scalar]{@link GraphQLUpload} to derive it’s value. Errors are\n * created with [`http-errors`](https://npm.im/http-errors) to assist in\n * sending responses with appropriate HTTP status codes. Used in\n * [`graphqlUploadExpress`]{@link graphqlUploadExpress} and\n * [`graphqlUploadKoa`]{@link graphqlUploadKoa} and can be used to create\n * custom middleware.\n * @kind function\n * @name processRequest\n * @type {ProcessRequestFunction}\n * @example <caption>Ways to `import`.</caption>\n * ```js\n * import { processRequest } from 'graphql-upload';\n * ```\n *\n * ```js\n * import processRequest from 'graphql-upload/public/processRequest.js';\n * ```\n * @example <caption>Ways to `require`.</caption>\n * ```js\n * const { processRequest } = require('graphql-upload');\n * ```\n *\n * ```js\n * const processRequest = require('graphql-upload/public/processRequest');\n * ```\n */\n\n\nmodule.exports = function processRequest(request, response, {\n  maxFieldSize = 1000000,\n  // 1 MB\n  maxFileSize = Infinity,\n  maxFiles = Infinity\n} = {}) {\n  return new Promise((resolve, reject) => {\n    let released;\n    let exitError;\n    let currentStream;\n    let operations;\n    let operationsPath;\n    let map;\n    const parser = new Busboy({\n      headers: request.headers,\n      limits: {\n        fieldSize: maxFieldSize,\n        fields: 2,\n        // Only operations and map.\n        fileSize: maxFileSize,\n        files: maxFiles\n      }\n    });\n    /**\n     * Exits request processing with an error. Successive calls have no effect.\n     * @kind function\n     * @name processRequest~exit\n     * @param {object} error Error instance.\n     * @ignore\n     */\n\n    const exit = error => {\n      if (exitError) return;\n      exitError = error;\n      reject(exitError);\n      parser.destroy();\n      if (currentStream) currentStream.destroy(exitError);\n      if (map) for (const upload of map.values()) if (!upload.file) upload.reject(exitError);\n      request.unpipe(parser); // With a sufficiently large request body, subsequent events in the same\n      // event frame cause the stream to pause after the parser is destroyed. To\n      // ensure that the request resumes, the call to .resume() is scheduled for\n      // later in the event loop.\n\n      setImmediate(() => {\n        request.resume();\n      });\n    };\n    /**\n     * Releases resources and cleans up Capacitor temporary files. Successive\n     * calls have no effect.\n     * @kind function\n     * @name processRequest~release\n     * @ignore\n     */\n\n\n    const release = () => {\n      if (released) return;\n      released = true;\n      if (map) for (const upload of map.values()) if (upload.file) upload.file.capacitor.release();\n    };\n    /**\n     * Handles when the request is closed before it properly ended.\n     * @kind function\n     * @name processRequest~abort\n     * @ignore\n     */\n\n\n    const abort = () => {\n      exit(createError(499, 'Request disconnected during file upload stream parsing.'));\n    };\n\n    parser.on('field', (fieldName, value, fieldNameTruncated, valueTruncated) => {\n      if (exitError) return;\n      if (valueTruncated) return exit(createError(413, `The ‘${fieldName}’ multipart field value exceeds the ${maxFieldSize} byte size limit.`));\n\n      switch (fieldName) {\n        case 'operations':\n          try {\n            operations = JSON.parse(value);\n          } catch (error) {\n            return exit(createError(400, `Invalid JSON in the ‘operations’ multipart field (${SPEC_URL}).`));\n          }\n\n          if (!isObject(operations) && !Array.isArray(operations)) return exit(createError(400, `Invalid type for the ‘operations’ multipart field (${SPEC_URL}).`));\n          operationsPath = objectPath(operations);\n          break;\n\n        case 'map':\n          {\n            if (!operations) return exit(createError(400, `Misordered multipart fields; ‘map’ should follow ‘operations’ (${SPEC_URL}).`));\n            let parsedMap;\n\n            try {\n              parsedMap = JSON.parse(value);\n            } catch (error) {\n              return exit(createError(400, `Invalid JSON in the ‘map’ multipart field (${SPEC_URL}).`));\n            }\n\n            if (!isObject(parsedMap)) return exit(createError(400, `Invalid type for the ‘map’ multipart field (${SPEC_URL}).`));\n            const mapEntries = Object.entries(parsedMap); // Check max files is not exceeded, even though the number of files to\n            // parse might not match th(e map provided by the client.\n\n            if (mapEntries.length > maxFiles) return exit(createError(413, `${maxFiles} max file uploads exceeded.`));\n            map = new Map();\n\n            for (const [fieldName, paths] of mapEntries) {\n              if (!Array.isArray(paths)) return exit(createError(400, `Invalid type for the ‘map’ multipart field entry key ‘${fieldName}’ array (${SPEC_URL}).`));\n              map.set(fieldName, new Upload());\n\n              for (const [index, path] of paths.entries()) {\n                if (typeof path !== 'string') return exit(createError(400, `Invalid type for the ‘map’ multipart field entry key ‘${fieldName}’ array index ‘${index}’ value (${SPEC_URL}).`));\n\n                try {\n                  operationsPath.set(path, map.get(fieldName));\n                } catch (error) {\n                  return exit(createError(400, `Invalid object path for the ‘map’ multipart field entry key ‘${fieldName}’ array index ‘${index}’ value ‘${path}’ (${SPEC_URL}).`));\n                }\n              }\n            }\n\n            resolve(operations);\n          }\n      }\n    });\n    parser.on('file', (fieldName, stream, filename, encoding, mimetype) => {\n      if (exitError) {\n        ignoreStream(stream);\n        return;\n      }\n\n      if (!map) {\n        ignoreStream(stream);\n        return exit(createError(400, `Misordered multipart fields; files should follow ‘map’ (${SPEC_URL}).`));\n      }\n\n      currentStream = stream;\n      stream.on('end', () => {\n        currentStream = null;\n      });\n      const upload = map.get(fieldName);\n\n      if (!upload) {\n        // The file is extraneous. As the rest can still be processed, just\n        // ignore it and don’t exit with an error.\n        ignoreStream(stream);\n        return;\n      }\n\n      let fileError;\n      const capacitor = new WriteStream();\n      capacitor.on('error', () => {\n        stream.unpipe();\n        stream.resume();\n      });\n      stream.on('limit', () => {\n        fileError = createError(413, `File truncated as it exceeds the ${maxFileSize} byte size limit.`);\n        stream.unpipe();\n        capacitor.destroy(fileError);\n      });\n      stream.on('error', error => {\n        fileError = error;\n        stream.unpipe();\n        capacitor.destroy(exitError);\n      });\n      const file = {\n        filename,\n        mimetype,\n        encoding,\n\n        createReadStream(options) {\n          const error = fileError || (released ? exitError : null);\n          if (error) throw error;\n          return capacitor.createReadStream(options);\n        }\n\n      };\n      Object.defineProperty(file, 'capacitor', {\n        value: capacitor\n      });\n      stream.pipe(capacitor);\n      upload.resolve(file);\n    });\n    parser.once('filesLimit', () => exit(createError(413, `${maxFiles} max file uploads exceeded.`)));\n    parser.once('finish', () => {\n      request.unpipe(parser);\n      request.resume();\n      if (!operations) return exit(createError(400, `Missing multipart field ‘operations’ (${SPEC_URL}).`));\n      if (!map) return exit(createError(400, `Missing multipart field ‘map’ (${SPEC_URL}).`));\n\n      for (const upload of map.values()) if (!upload.file) upload.reject(createError(400, 'File missing in the request.'));\n    });\n    parser.once('error', exit);\n    response.once('finish', release);\n    response.once('close', release);\n    request.once('close', abort);\n    request.once('end', () => {\n      request.removeListener('close', abort);\n    });\n    request.pipe(parser);\n  });\n};","map":{"version":3,"sources":["C:/Users/Admin/programs/django+react/tutorials/graphql_django/frontend/gui/node_modules/graphql-upload/public/processRequest.js"],"names":["Busboy","require","WriteStream","createError","isObject","objectPath","SPEC_URL","ignoreStream","Upload","module","exports","processRequest","request","response","maxFieldSize","maxFileSize","Infinity","maxFiles","Promise","resolve","reject","released","exitError","currentStream","operations","operationsPath","map","parser","headers","limits","fieldSize","fields","fileSize","files","exit","error","destroy","upload","values","file","unpipe","setImmediate","resume","release","capacitor","abort","on","fieldName","value","fieldNameTruncated","valueTruncated","JSON","parse","Array","isArray","parsedMap","mapEntries","Object","entries","length","Map","paths","set","index","path","get","stream","filename","encoding","mimetype","fileError","createReadStream","options","defineProperty","pipe","once","removeListener"],"mappings":"AAAA;;AAEA,MAAMA,MAAM,GAAGC,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAM;AAAEC,EAAAA;AAAF,IAAkBD,OAAO,CAAC,cAAD,CAA/B;;AACA,MAAME,WAAW,GAAGF,OAAO,CAAC,aAAD,CAA3B;;AACA,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAD,CAAxB;;AACA,MAAMI,UAAU,GAAGJ,OAAO,CAAC,aAAD,CAA1B;;AACA,MAAM;AAAEK,EAAAA;AAAF,IAAeL,OAAO,CAAC,sBAAD,CAA5B;;AACA,MAAMM,YAAY,GAAGN,OAAO,CAAC,yBAAD,CAA5B;;AACA,MAAMO,MAAM,GAAGP,OAAO,CAAC,UAAD,CAAtB;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCAQ,MAAM,CAACC,OAAP,GAAiB,SAASC,cAAT,CACfC,OADe,EAEfC,QAFe,EAGf;AACEC,EAAAA,YAAY,GAAG,OADjB;AAC0B;AACxBC,EAAAA,WAAW,GAAGC,QAFhB;AAGEC,EAAAA,QAAQ,GAAGD;AAHb,IAII,EAPW,EAQf;AACA,SAAO,IAAIE,OAAJ,CAAY,CAACC,OAAD,EAAUC,MAAV,KAAqB;AACtC,QAAIC,QAAJ;AACA,QAAIC,SAAJ;AACA,QAAIC,aAAJ;AACA,QAAIC,UAAJ;AACA,QAAIC,cAAJ;AACA,QAAIC,GAAJ;AAEA,UAAMC,MAAM,GAAG,IAAI3B,MAAJ,CAAW;AACxB4B,MAAAA,OAAO,EAAEhB,OAAO,CAACgB,OADO;AAExBC,MAAAA,MAAM,EAAE;AACNC,QAAAA,SAAS,EAAEhB,YADL;AAENiB,QAAAA,MAAM,EAAE,CAFF;AAEK;AACXC,QAAAA,QAAQ,EAAEjB,WAHJ;AAINkB,QAAAA,KAAK,EAAEhB;AAJD;AAFgB,KAAX,CAAf;AAUA;;;;;;;;AAOA,UAAMiB,IAAI,GAAIC,KAAD,IAAW;AACtB,UAAIb,SAAJ,EAAe;AACfA,MAAAA,SAAS,GAAGa,KAAZ;AAEAf,MAAAA,MAAM,CAACE,SAAD,CAAN;AAEAK,MAAAA,MAAM,CAACS,OAAP;AAEA,UAAIb,aAAJ,EAAmBA,aAAa,CAACa,OAAd,CAAsBd,SAAtB;AAEnB,UAAII,GAAJ,EACE,KAAK,MAAMW,MAAX,IAAqBX,GAAG,CAACY,MAAJ,EAArB,EACE,IAAI,CAACD,MAAM,CAACE,IAAZ,EAAkBF,MAAM,CAACjB,MAAP,CAAcE,SAAd;AAEtBV,MAAAA,OAAO,CAAC4B,MAAR,CAAeb,MAAf,EAdsB,CAgBtB;AACA;AACA;AACA;;AACAc,MAAAA,YAAY,CAAC,MAAM;AACjB7B,QAAAA,OAAO,CAAC8B,MAAR;AACD,OAFW,CAAZ;AAGD,KAvBD;AAyBA;;;;;;;;;AAOA,UAAMC,OAAO,GAAG,MAAM;AACpB,UAAItB,QAAJ,EAAc;AACdA,MAAAA,QAAQ,GAAG,IAAX;AAEA,UAAIK,GAAJ,EACE,KAAK,MAAMW,MAAX,IAAqBX,GAAG,CAACY,MAAJ,EAArB,EACE,IAAID,MAAM,CAACE,IAAX,EAAiBF,MAAM,CAACE,IAAP,CAAYK,SAAZ,CAAsBD,OAAtB;AACtB,KAPD;AASA;;;;;;;;AAMA,UAAME,KAAK,GAAG,MAAM;AAClBX,MAAAA,IAAI,CACF/B,WAAW,CACT,GADS,EAET,yDAFS,CADT,CAAJ;AAMD,KAPD;;AASAwB,IAAAA,MAAM,CAACmB,EAAP,CACE,OADF,EAEE,CAACC,SAAD,EAAYC,KAAZ,EAAmBC,kBAAnB,EAAuCC,cAAvC,KAA0D;AACxD,UAAI5B,SAAJ,EAAe;AAEf,UAAI4B,cAAJ,EACE,OAAOhB,IAAI,CACT/B,WAAW,CACT,GADS,EAER,QAAO4C,SAAU,uCAAsCjC,YAAa,mBAF5D,CADF,CAAX;;AAOF,cAAQiC,SAAR;AACE,aAAK,YAAL;AACE,cAAI;AACFvB,YAAAA,UAAU,GAAG2B,IAAI,CAACC,KAAL,CAAWJ,KAAX,CAAb;AACD,WAFD,CAEE,OAAOb,KAAP,EAAc;AACd,mBAAOD,IAAI,CACT/B,WAAW,CACT,GADS,EAER,qDAAoDG,QAAS,IAFrD,CADF,CAAX;AAMD;;AAED,cAAI,CAACF,QAAQ,CAACoB,UAAD,CAAT,IAAyB,CAAC6B,KAAK,CAACC,OAAN,CAAc9B,UAAd,CAA9B,EACE,OAAOU,IAAI,CACT/B,WAAW,CACT,GADS,EAER,sDAAqDG,QAAS,IAFtD,CADF,CAAX;AAOFmB,UAAAA,cAAc,GAAGpB,UAAU,CAACmB,UAAD,CAA3B;AAEA;;AACF,aAAK,KAAL;AAAY;AACV,gBAAI,CAACA,UAAL,EACE,OAAOU,IAAI,CACT/B,WAAW,CACT,GADS,EAER,kEAAiEG,QAAS,IAFlE,CADF,CAAX;AAOF,gBAAIiD,SAAJ;;AACA,gBAAI;AACFA,cAAAA,SAAS,GAAGJ,IAAI,CAACC,KAAL,CAAWJ,KAAX,CAAZ;AACD,aAFD,CAEE,OAAOb,KAAP,EAAc;AACd,qBAAOD,IAAI,CACT/B,WAAW,CACT,GADS,EAER,8CAA6CG,QAAS,IAF9C,CADF,CAAX;AAMD;;AAED,gBAAI,CAACF,QAAQ,CAACmD,SAAD,CAAb,EACE,OAAOrB,IAAI,CACT/B,WAAW,CACT,GADS,EAER,+CAA8CG,QAAS,IAF/C,CADF,CAAX;AAOF,kBAAMkD,UAAU,GAAGC,MAAM,CAACC,OAAP,CAAeH,SAAf,CAAnB,CA7BU,CA+BV;AACA;;AACA,gBAAIC,UAAU,CAACG,MAAX,GAAoB1C,QAAxB,EACE,OAAOiB,IAAI,CACT/B,WAAW,CAAC,GAAD,EAAO,GAAEc,QAAS,6BAAlB,CADF,CAAX;AAIFS,YAAAA,GAAG,GAAG,IAAIkC,GAAJ,EAAN;;AACA,iBAAK,MAAM,CAACb,SAAD,EAAYc,KAAZ,CAAX,IAAiCL,UAAjC,EAA6C;AAC3C,kBAAI,CAACH,KAAK,CAACC,OAAN,CAAcO,KAAd,CAAL,EACE,OAAO3B,IAAI,CACT/B,WAAW,CACT,GADS,EAER,yDAAwD4C,SAAU,YAAWzC,QAAS,IAF9E,CADF,CAAX;AAOFoB,cAAAA,GAAG,CAACoC,GAAJ,CAAQf,SAAR,EAAmB,IAAIvC,MAAJ,EAAnB;;AAEA,mBAAK,MAAM,CAACuD,KAAD,EAAQC,IAAR,CAAX,IAA4BH,KAAK,CAACH,OAAN,EAA5B,EAA6C;AAC3C,oBAAI,OAAOM,IAAP,KAAgB,QAApB,EACE,OAAO9B,IAAI,CACT/B,WAAW,CACT,GADS,EAER,yDAAwD4C,SAAU,kBAAiBgB,KAAM,YAAWzD,QAAS,IAFrG,CADF,CAAX;;AAOF,oBAAI;AACFmB,kBAAAA,cAAc,CAACqC,GAAf,CAAmBE,IAAnB,EAAyBtC,GAAG,CAACuC,GAAJ,CAAQlB,SAAR,CAAzB;AACD,iBAFD,CAEE,OAAOZ,KAAP,EAAc;AACd,yBAAOD,IAAI,CACT/B,WAAW,CACT,GADS,EAER,gEAA+D4C,SAAU,kBAAiBgB,KAAM,YAAWC,IAAK,MAAK1D,QAAS,IAFtH,CADF,CAAX;AAMD;AACF;AACF;;AAEDa,YAAAA,OAAO,CAACK,UAAD,CAAP;AACD;AAjGH;AAmGD,KAhHH;AAmHAG,IAAAA,MAAM,CAACmB,EAAP,CAAU,MAAV,EAAkB,CAACC,SAAD,EAAYmB,MAAZ,EAAoBC,QAApB,EAA8BC,QAA9B,EAAwCC,QAAxC,KAAqD;AACrE,UAAI/C,SAAJ,EAAe;AACbf,QAAAA,YAAY,CAAC2D,MAAD,CAAZ;AACA;AACD;;AAED,UAAI,CAACxC,GAAL,EAAU;AACRnB,QAAAA,YAAY,CAAC2D,MAAD,CAAZ;AACA,eAAOhC,IAAI,CACT/B,WAAW,CACT,GADS,EAER,2DAA0DG,QAAS,IAF3D,CADF,CAAX;AAMD;;AAEDiB,MAAAA,aAAa,GAAG2C,MAAhB;AACAA,MAAAA,MAAM,CAACpB,EAAP,CAAU,KAAV,EAAiB,MAAM;AACrBvB,QAAAA,aAAa,GAAG,IAAhB;AACD,OAFD;AAIA,YAAMc,MAAM,GAAGX,GAAG,CAACuC,GAAJ,CAAQlB,SAAR,CAAf;;AAEA,UAAI,CAACV,MAAL,EAAa;AACX;AACA;AACA9B,QAAAA,YAAY,CAAC2D,MAAD,CAAZ;AACA;AACD;;AAED,UAAII,SAAJ;AACA,YAAM1B,SAAS,GAAG,IAAI1C,WAAJ,EAAlB;AAEA0C,MAAAA,SAAS,CAACE,EAAV,CAAa,OAAb,EAAsB,MAAM;AAC1BoB,QAAAA,MAAM,CAAC1B,MAAP;AACA0B,QAAAA,MAAM,CAACxB,MAAP;AACD,OAHD;AAKAwB,MAAAA,MAAM,CAACpB,EAAP,CAAU,OAAV,EAAmB,MAAM;AACvBwB,QAAAA,SAAS,GAAGnE,WAAW,CACrB,GADqB,EAEpB,oCAAmCY,WAAY,mBAF3B,CAAvB;AAIAmD,QAAAA,MAAM,CAAC1B,MAAP;AACAI,QAAAA,SAAS,CAACR,OAAV,CAAkBkC,SAAlB;AACD,OAPD;AASAJ,MAAAA,MAAM,CAACpB,EAAP,CAAU,OAAV,EAAoBX,KAAD,IAAW;AAC5BmC,QAAAA,SAAS,GAAGnC,KAAZ;AACA+B,QAAAA,MAAM,CAAC1B,MAAP;AACAI,QAAAA,SAAS,CAACR,OAAV,CAAkBd,SAAlB;AACD,OAJD;AAMA,YAAMiB,IAAI,GAAG;AACX4B,QAAAA,QADW;AAEXE,QAAAA,QAFW;AAGXD,QAAAA,QAHW;;AAIXG,QAAAA,gBAAgB,CAACC,OAAD,EAAU;AACxB,gBAAMrC,KAAK,GAAGmC,SAAS,KAAKjD,QAAQ,GAAGC,SAAH,GAAe,IAA5B,CAAvB;AACA,cAAIa,KAAJ,EAAW,MAAMA,KAAN;AACX,iBAAOS,SAAS,CAAC2B,gBAAV,CAA2BC,OAA3B,CAAP;AACD;;AARU,OAAb;AAWAf,MAAAA,MAAM,CAACgB,cAAP,CAAsBlC,IAAtB,EAA4B,WAA5B,EAAyC;AAAES,QAAAA,KAAK,EAAEJ;AAAT,OAAzC;AAEAsB,MAAAA,MAAM,CAACQ,IAAP,CAAY9B,SAAZ;AACAP,MAAAA,MAAM,CAAClB,OAAP,CAAeoB,IAAf;AACD,KApED;AAsEAZ,IAAAA,MAAM,CAACgD,IAAP,CAAY,YAAZ,EAA0B,MACxBzC,IAAI,CAAC/B,WAAW,CAAC,GAAD,EAAO,GAAEc,QAAS,6BAAlB,CAAZ,CADN;AAIAU,IAAAA,MAAM,CAACgD,IAAP,CAAY,QAAZ,EAAsB,MAAM;AAC1B/D,MAAAA,OAAO,CAAC4B,MAAR,CAAeb,MAAf;AACAf,MAAAA,OAAO,CAAC8B,MAAR;AAEA,UAAI,CAAClB,UAAL,EACE,OAAOU,IAAI,CACT/B,WAAW,CACT,GADS,EAER,yCAAwCG,QAAS,IAFzC,CADF,CAAX;AAOF,UAAI,CAACoB,GAAL,EACE,OAAOQ,IAAI,CACT/B,WAAW,CAAC,GAAD,EAAO,kCAAiCG,QAAS,IAAjD,CADF,CAAX;;AAIF,WAAK,MAAM+B,MAAX,IAAqBX,GAAG,CAACY,MAAJ,EAArB,EACE,IAAI,CAACD,MAAM,CAACE,IAAZ,EACEF,MAAM,CAACjB,MAAP,CAAcjB,WAAW,CAAC,GAAD,EAAM,8BAAN,CAAzB;AACL,KApBD;AAsBAwB,IAAAA,MAAM,CAACgD,IAAP,CAAY,OAAZ,EAAqBzC,IAArB;AAEArB,IAAAA,QAAQ,CAAC8D,IAAT,CAAc,QAAd,EAAwBhC,OAAxB;AACA9B,IAAAA,QAAQ,CAAC8D,IAAT,CAAc,OAAd,EAAuBhC,OAAvB;AAEA/B,IAAAA,OAAO,CAAC+D,IAAR,CAAa,OAAb,EAAsB9B,KAAtB;AACAjC,IAAAA,OAAO,CAAC+D,IAAR,CAAa,KAAb,EAAoB,MAAM;AACxB/D,MAAAA,OAAO,CAACgE,cAAR,CAAuB,OAAvB,EAAgC/B,KAAhC;AACD,KAFD;AAIAjC,IAAAA,OAAO,CAAC8D,IAAR,CAAa/C,MAAb;AACD,GA/SM,CAAP;AAgTD,CAzTD","sourcesContent":["'use strict';\n\nconst Busboy = require('busboy');\nconst { WriteStream } = require('fs-capacitor');\nconst createError = require('http-errors');\nconst isObject = require('isobject');\nconst objectPath = require('object-path');\nconst { SPEC_URL } = require('../private/constants');\nconst ignoreStream = require('../private/ignoreStream');\nconst Upload = require('./Upload');\n\n/**\n * Processes a [GraphQL multipart request](https://github.com/jaydenseric/graphql-multipart-request-spec).\n * It parses the `operations` and `map` fields to create an\n * [`Upload`]{@link Upload} instance for each expected file upload, placing\n * references wherever the file is expected in the\n * [GraphQL operation]{@link GraphQLOperation} for the\n * [`Upload` scalar]{@link GraphQLUpload} to derive it’s value. Errors are\n * created with [`http-errors`](https://npm.im/http-errors) to assist in\n * sending responses with appropriate HTTP status codes. Used in\n * [`graphqlUploadExpress`]{@link graphqlUploadExpress} and\n * [`graphqlUploadKoa`]{@link graphqlUploadKoa} and can be used to create\n * custom middleware.\n * @kind function\n * @name processRequest\n * @type {ProcessRequestFunction}\n * @example <caption>Ways to `import`.</caption>\n * ```js\n * import { processRequest } from 'graphql-upload';\n * ```\n *\n * ```js\n * import processRequest from 'graphql-upload/public/processRequest.js';\n * ```\n * @example <caption>Ways to `require`.</caption>\n * ```js\n * const { processRequest } = require('graphql-upload');\n * ```\n *\n * ```js\n * const processRequest = require('graphql-upload/public/processRequest');\n * ```\n */\nmodule.exports = function processRequest(\n  request,\n  response,\n  {\n    maxFieldSize = 1000000, // 1 MB\n    maxFileSize = Infinity,\n    maxFiles = Infinity,\n  } = {}\n) {\n  return new Promise((resolve, reject) => {\n    let released;\n    let exitError;\n    let currentStream;\n    let operations;\n    let operationsPath;\n    let map;\n\n    const parser = new Busboy({\n      headers: request.headers,\n      limits: {\n        fieldSize: maxFieldSize,\n        fields: 2, // Only operations and map.\n        fileSize: maxFileSize,\n        files: maxFiles,\n      },\n    });\n\n    /**\n     * Exits request processing with an error. Successive calls have no effect.\n     * @kind function\n     * @name processRequest~exit\n     * @param {object} error Error instance.\n     * @ignore\n     */\n    const exit = (error) => {\n      if (exitError) return;\n      exitError = error;\n\n      reject(exitError);\n\n      parser.destroy();\n\n      if (currentStream) currentStream.destroy(exitError);\n\n      if (map)\n        for (const upload of map.values())\n          if (!upload.file) upload.reject(exitError);\n\n      request.unpipe(parser);\n\n      // With a sufficiently large request body, subsequent events in the same\n      // event frame cause the stream to pause after the parser is destroyed. To\n      // ensure that the request resumes, the call to .resume() is scheduled for\n      // later in the event loop.\n      setImmediate(() => {\n        request.resume();\n      });\n    };\n\n    /**\n     * Releases resources and cleans up Capacitor temporary files. Successive\n     * calls have no effect.\n     * @kind function\n     * @name processRequest~release\n     * @ignore\n     */\n    const release = () => {\n      if (released) return;\n      released = true;\n\n      if (map)\n        for (const upload of map.values())\n          if (upload.file) upload.file.capacitor.release();\n    };\n\n    /**\n     * Handles when the request is closed before it properly ended.\n     * @kind function\n     * @name processRequest~abort\n     * @ignore\n     */\n    const abort = () => {\n      exit(\n        createError(\n          499,\n          'Request disconnected during file upload stream parsing.'\n        )\n      );\n    };\n\n    parser.on(\n      'field',\n      (fieldName, value, fieldNameTruncated, valueTruncated) => {\n        if (exitError) return;\n\n        if (valueTruncated)\n          return exit(\n            createError(\n              413,\n              `The ‘${fieldName}’ multipart field value exceeds the ${maxFieldSize} byte size limit.`\n            )\n          );\n\n        switch (fieldName) {\n          case 'operations':\n            try {\n              operations = JSON.parse(value);\n            } catch (error) {\n              return exit(\n                createError(\n                  400,\n                  `Invalid JSON in the ‘operations’ multipart field (${SPEC_URL}).`\n                )\n              );\n            }\n\n            if (!isObject(operations) && !Array.isArray(operations))\n              return exit(\n                createError(\n                  400,\n                  `Invalid type for the ‘operations’ multipart field (${SPEC_URL}).`\n                )\n              );\n\n            operationsPath = objectPath(operations);\n\n            break;\n          case 'map': {\n            if (!operations)\n              return exit(\n                createError(\n                  400,\n                  `Misordered multipart fields; ‘map’ should follow ‘operations’ (${SPEC_URL}).`\n                )\n              );\n\n            let parsedMap;\n            try {\n              parsedMap = JSON.parse(value);\n            } catch (error) {\n              return exit(\n                createError(\n                  400,\n                  `Invalid JSON in the ‘map’ multipart field (${SPEC_URL}).`\n                )\n              );\n            }\n\n            if (!isObject(parsedMap))\n              return exit(\n                createError(\n                  400,\n                  `Invalid type for the ‘map’ multipart field (${SPEC_URL}).`\n                )\n              );\n\n            const mapEntries = Object.entries(parsedMap);\n\n            // Check max files is not exceeded, even though the number of files to\n            // parse might not match th(e map provided by the client.\n            if (mapEntries.length > maxFiles)\n              return exit(\n                createError(413, `${maxFiles} max file uploads exceeded.`)\n              );\n\n            map = new Map();\n            for (const [fieldName, paths] of mapEntries) {\n              if (!Array.isArray(paths))\n                return exit(\n                  createError(\n                    400,\n                    `Invalid type for the ‘map’ multipart field entry key ‘${fieldName}’ array (${SPEC_URL}).`\n                  )\n                );\n\n              map.set(fieldName, new Upload());\n\n              for (const [index, path] of paths.entries()) {\n                if (typeof path !== 'string')\n                  return exit(\n                    createError(\n                      400,\n                      `Invalid type for the ‘map’ multipart field entry key ‘${fieldName}’ array index ‘${index}’ value (${SPEC_URL}).`\n                    )\n                  );\n\n                try {\n                  operationsPath.set(path, map.get(fieldName));\n                } catch (error) {\n                  return exit(\n                    createError(\n                      400,\n                      `Invalid object path for the ‘map’ multipart field entry key ‘${fieldName}’ array index ‘${index}’ value ‘${path}’ (${SPEC_URL}).`\n                    )\n                  );\n                }\n              }\n            }\n\n            resolve(operations);\n          }\n        }\n      }\n    );\n\n    parser.on('file', (fieldName, stream, filename, encoding, mimetype) => {\n      if (exitError) {\n        ignoreStream(stream);\n        return;\n      }\n\n      if (!map) {\n        ignoreStream(stream);\n        return exit(\n          createError(\n            400,\n            `Misordered multipart fields; files should follow ‘map’ (${SPEC_URL}).`\n          )\n        );\n      }\n\n      currentStream = stream;\n      stream.on('end', () => {\n        currentStream = null;\n      });\n\n      const upload = map.get(fieldName);\n\n      if (!upload) {\n        // The file is extraneous. As the rest can still be processed, just\n        // ignore it and don’t exit with an error.\n        ignoreStream(stream);\n        return;\n      }\n\n      let fileError;\n      const capacitor = new WriteStream();\n\n      capacitor.on('error', () => {\n        stream.unpipe();\n        stream.resume();\n      });\n\n      stream.on('limit', () => {\n        fileError = createError(\n          413,\n          `File truncated as it exceeds the ${maxFileSize} byte size limit.`\n        );\n        stream.unpipe();\n        capacitor.destroy(fileError);\n      });\n\n      stream.on('error', (error) => {\n        fileError = error;\n        stream.unpipe();\n        capacitor.destroy(exitError);\n      });\n\n      const file = {\n        filename,\n        mimetype,\n        encoding,\n        createReadStream(options) {\n          const error = fileError || (released ? exitError : null);\n          if (error) throw error;\n          return capacitor.createReadStream(options);\n        },\n      };\n\n      Object.defineProperty(file, 'capacitor', { value: capacitor });\n\n      stream.pipe(capacitor);\n      upload.resolve(file);\n    });\n\n    parser.once('filesLimit', () =>\n      exit(createError(413, `${maxFiles} max file uploads exceeded.`))\n    );\n\n    parser.once('finish', () => {\n      request.unpipe(parser);\n      request.resume();\n\n      if (!operations)\n        return exit(\n          createError(\n            400,\n            `Missing multipart field ‘operations’ (${SPEC_URL}).`\n          )\n        );\n\n      if (!map)\n        return exit(\n          createError(400, `Missing multipart field ‘map’ (${SPEC_URL}).`)\n        );\n\n      for (const upload of map.values())\n        if (!upload.file)\n          upload.reject(createError(400, 'File missing in the request.'));\n    });\n\n    parser.once('error', exit);\n\n    response.once('finish', release);\n    response.once('close', release);\n\n    request.once('close', abort);\n    request.once('end', () => {\n      request.removeListener('close', abort);\n    });\n\n    request.pipe(parser);\n  });\n};\n"]},"metadata":{},"sourceType":"script"}